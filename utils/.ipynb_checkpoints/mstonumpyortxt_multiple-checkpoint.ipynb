{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert visibilities from CASA MS format to Python save file\n",
    "To be executed in CASA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "sourcetag,workingdir,vis,nvis,mosaic,phasecenter,weighting,robust,uvtaper,interactive = pickle.load(open('../imaging/imagepars.npy','rb'))\n",
    "vis=[x.encode('ascii') for x in vis]\n",
    "\n",
    "tb = casac.table()\n",
    "ms = casac.ms()\n",
    "cc=2.9979e10 #cm/s\n",
    "    \n",
    "#Use CASA table tools to get columns of UVW, DATA, WEIGHT, etc.\n",
    "outputfilename=[x[:-3]+'.npy' for x in vis]\n",
    "tb = casac.table()\n",
    "ms = casac.ms()\n",
    "cc=2.9979e10 #cm/s\n",
    "    \n",
    "#Use CASA table tools to get columns of UVW, DATA, WEIGHT, etc.\n",
    "filename=vis\n",
    "\n",
    "for ii in np.arange(len(filename)):\n",
    "    tb.open(filename[ii])\n",
    "    #NB for this to run smooth we need to have the same number of channels for ALL scans. So no spectral windows with different number of channels, otherwise it gets complicated.\n",
    "    #See https://safe.nrao.edu/wiki/pub/Main/RadioTutorial/BandwidthSmearing.pdf to choose how much to smooth a dataset in frequency.\n",
    "    #Errors are taking into account when time averaging in split: https://casa.nrao.edu/casadocs/casa-5.1.1/uv-manipulation/time-average\n",
    "    #And when channel averaging: https://casa.nrao.edu/casadocs/casa-5.1.1/uv-manipulation/channel-average\n",
    "    data    = tb.getcol(\"DATA\")\n",
    "    uvw     = tb.getcol(\"UVW\")\n",
    "    flags   = tb.getcol(\"FLAG\")\n",
    "    spwid   = tb.getcol(\"DATA_DESC_ID\")\n",
    "    weight  = tb.getcol(\"WEIGHT\")\n",
    "    ant1    = tb.getcol(\"ANTENNA1\")\n",
    "    ant2    = tb.getcol(\"ANTENNA2\")\n",
    "    tb.close()\n",
    "    if np.any(flags):\n",
    "        print \"Note: some of the data is FLAGGED\"\n",
    "    print \"Found data with \"+str(data.shape[-1])+\" uv points per channel\"\n",
    "\n",
    "\n",
    "    #Use CASA ms tools to get the channel/spw info\n",
    "    ms.open(filename[ii])\n",
    "    spwstuff = ms.getspectralwindowinfo()\n",
    "    nchan = spwstuff[\"0\"][\"NumChan\"]\n",
    "    npol = spwstuff[\"0\"][\"NumCorr\"]\n",
    "    ms.close()\n",
    "    print \"with \"+str(nchan)+\" channels per SPW and \"+str(npol)+\" polarizations,\"\n",
    "\n",
    "    #Use CASA table tools to get frequencies, which are needed to calculate u-v points from baseline lengths\n",
    "    tb.open(filename[ii]+\"/SPECTRAL_WINDOW\")\n",
    "    freqs = tb.getcol(\"CHAN_FREQ\")\n",
    "    rfreq = tb.getcol(\"REF_FREQUENCY\")\n",
    "    tb.close()\n",
    "    print str(freqs.shape[1])+\" SPWs and Channel 0 frequency of 1st SPW of \"+str(rfreq[0]/1e9)+\" GHz\"\n",
    "    print \"corresponding to \"+str(2.9979e8/rfreq[0]*1e3)+\" mm\"\n",
    "\n",
    "    print \"Datasets has baselines between \"+str(np.min(np.sqrt(uvw[0,:]**2.0+uvw[1,:]**2.0)))+\" and \"+str(np.max(np.sqrt(uvw[0,:]**2.0+uvw[1,:]**2.0)))+\" m\"  \n",
    "\n",
    "    #Initialize u and v arrays (coordinates in Fourier space)\n",
    "    uu=np.zeros((freqs.shape[0],uvw[0,:].size))\n",
    "    vv=np.zeros((freqs.shape[0],uvw[0,:].size))\n",
    "\n",
    "    #Fill u and v arrays appropriately from data values.\n",
    "    for i in np.arange(freqs.shape[0]):        \n",
    "        for j in np.arange(uvw.shape[1]):\n",
    "            uu[i,j]=uvw[0,j]*freqs[i,spwid[j]]/(cc/100.0)\n",
    "            vv[i,j]=uvw[1,j]*freqs[i,spwid[j]]/(cc/100.0)\n",
    "\n",
    "    #Extract real and imaginary part of the visibilities at all u-v coordinates, for both polarization states (XX and YY), extract weights which correspond to 1/(uncertainty)^2\n",
    "    Re_xx = data[0,:,:].real\n",
    "    Im_xx = data[0,:,:].imag\n",
    "    weight_xx = weight[0,:]\n",
    "    if npol>=2:\n",
    "        Re_yy = data[1,:,:].real\n",
    "        Im_yy = data[1,:,:].imag\n",
    "        weight_yy = weight[1,:]\n",
    "        #print('Ciao')\n",
    "\n",
    "        #Since we don't care about polarization, combine polarization states (average them together) and fix the weights accordingly. Also if any of the two polarization states is flagged, flag the outcome of the combination.\n",
    "        flags = flags[0,:,:]*flags[1,:,:]\n",
    "        Re = np.where((weight_xx + weight_yy) != 0, (Re_xx*weight_xx + Re_yy*weight_yy) / (weight_xx + weight_yy), 0.)\n",
    "        Im = np.where((weight_xx + weight_yy) != 0, (Im_xx*weight_xx + Im_yy*weight_yy) / (weight_xx + weight_yy), 0.)\n",
    "        wgts = (weight_xx + weight_yy)\n",
    "    else:\n",
    "        Re=Re_xx\n",
    "        Im=Im_xx\n",
    "        wgts=weight_xx\n",
    "        flags=flags[0,:,:]\n",
    "\n",
    "    # Find which of the data represents cross-correlation between two antennas as opposed to auto-correlation of a single antenna.\n",
    "    # We don't care about the latter so we don't want it.\n",
    "    xc = np.where(ant1 != ant2)[0]\n",
    "    \n",
    "    #Select only cross-correlation data\n",
    "    data_real = Re[:,xc]\n",
    "    data_imag = Im[:,xc]\n",
    "    flags = flags[:,xc]\n",
    "    data_wgts = wgts[xc]\n",
    "    data_uu = uu[:,xc]\n",
    "    data_vv = vv[:,xc]\n",
    "    data_wgts=np.reshape(np.repeat(wgts[xc], uu.shape[0]), data_uu.shape)\n",
    "    #Delete previously used (and not needed) variables (to free up some memory?)\n",
    "    del Re\n",
    "    del Im\n",
    "    del wgts\n",
    "    del uu\n",
    "    del vv\n",
    "\n",
    "    #Select only data that is NOT flagged\n",
    "    data_real = data_real[np.logical_not(flags)]\n",
    "    data_imag = data_imag[np.logical_not(flags)]\n",
    "    flagss = flags[np.logical_not(flags)]\n",
    "    data_wgts = data_wgts[np.logical_not(flags)]\n",
    "    data_uu = data_uu[np.logical_not(flags)]\n",
    "    data_vv = data_vv[np.logical_not(flags)]\n",
    "\n",
    "    #Wrap up all the arrays/matrices we need, (u-v coordinates, complex visibilities, and weights for each visibility) and save them all together in a numpy file\n",
    "    u, v, Re, Im, w = data_uu, data_vv, data_real, data_imag, data_wgts\n",
    "    #print(filename[ii][:-3]+'.npy')\n",
    "    np.save(filename[ii][:-3]+'.npy', [u, v, Re, Im, w]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
