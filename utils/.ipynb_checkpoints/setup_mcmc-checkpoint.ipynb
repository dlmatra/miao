{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampler(backendaddress):\n",
    "    #Import general python packages\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as pl\n",
    "    import os\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    import astropy.io.fits as pf\n",
    "    import uuid\n",
    "    from galario.double import chi2Image, sampleImage, threads, get_image_size, sweep\n",
    "    threads(1)\n",
    "\n",
    "    c = 299792458.0\n",
    "\n",
    "    #Import fit parameters printed within main.py\n",
    "    pbfilenames,vis,nvis,radmcgalapath,workingdir,sourcetag,Lstar,dist,imsize,useh,star,\n",
    "                 ,ngal,resolved, pars_init, priors_dwn, priors_up = pickle.load(open('./fitpars.npy','rb'))\n",
    "    rmid_init=pars_init[1]\n",
    "    sigma_init=pars_init[2]\n",
    "        \n",
    "\n",
    "    #Import pixel and image sizes needed by galario\n",
    "    dxy, nxy = pickle.load(open('../calibratedms/pixinfo.npy','rb')) #NB dxy in radians\n",
    "    dxyarcsec=dxy*180.0/np.pi*3600.0\n",
    "\n",
    "    #Import necessary scripts and libraries within radmc-gala\n",
    "    os.sys.path.append(radmcgalapath+'/utils')\n",
    "    import problem_setup_cont_gauss\n",
    "    os.sys.path.append(radmcgalapath+'/src')\n",
    "    import emcee3\n",
    "    os.sys.path.append(radmcgalapath+'/radmc-3d/version_0.41/python')\n",
    "    import radmc3dPy\n",
    "\n",
    "    #### SYSTEM-SPECIFIC INPUTS ####\n",
    "    tag=sourcetag\n",
    "    npix=np.int(np.ceil(imsize/(dxyarcsec)/2.0)*2) #Needs to be EVEN. Pixels you actually want to compute radiative transfer over, depends on size of disk.\n",
    "    imszarcsec=imsize\n",
    "    sizeau=imszarcsec*dist\n",
    "\n",
    "    #### GRID INPUT TO BE THE SAME AS IN PROBLEM_SETUP CODE (used for temperature grid) ####\n",
    "    nr=8.0*sigma_init/(np.min(dxyarcsec)) #Make sure to cover entire width of disk at radial step equal to smallest pixel size of any dataset.\n",
    "    AU  = 1.49598e13     # Astronomical Unit       [cm]\n",
    "    rmin=np.max([1.0,rmid_init-4.*sigma_init])*dist*AU\n",
    "    rmax=np.min([np.min(dxyarcsec*nxy)/2.0,rmid_init+4.*sigma_init])*dist*AU\n",
    "    tcsize=20\n",
    "    ri=(np.arange(nr+1, dtype=float))/nr*(rmax-rmin)+rmin\n",
    "    dr=(np.subtract(ri[1:],ri[:-1]))\n",
    "    rc=np.asarray(ri[:-1]+dr/2e0)\n",
    "    rr=np.reshape(np.repeat(rc, tcsize), (rc.size, tcsize))\n",
    "\n",
    "    ### THIS GOES OUTSIDE MODEL RUN\n",
    "    # Write dummy wavelength file\n",
    "    lambda1 = 0.1e0\n",
    "    lambda2 = 7.0e0\n",
    "    lambda3 = 25.e0\n",
    "    lambda4 = 1.0e4\n",
    "    n12     = 20\n",
    "    n23     = 100\n",
    "    n34     = 30\n",
    "    lam12   = lambda1 * (lambda2/lambda1)**(np.arange(n12, dtype=float)/(1.e0*n12))\n",
    "    lam23   = lambda2 * (lambda3/lambda2)**(np.arange(n23, dtype=float)/(1.e0*n23))\n",
    "    lam34   = lambda3 * (lambda4/lambda3)**(np.arange(n34, dtype=float)/(1.e0*(n34-1.e0)))\n",
    "    lambd = np.concatenate((lam12,lam23,lam34))\n",
    "    nlam    = len(lambd)\n",
    "    wfile = open('wavelength_micron.inp', 'w')\n",
    "    wfile.write('%d\\n'%nlam)\n",
    "    for ilam in range(nlam): wfile.write('%.9e\\n'%lambd[ilam])\n",
    "    wfile.close()\n",
    "\n",
    "    # Write the radmc3d.inp control file\n",
    "    wfile = open('./radmc3d.inp', 'w')\n",
    "    #wfile.write('%s %d\\n'%('nphot'+' =',nphot))\n",
    "    wfile.write('%s %s\\n'%('scattering_mode_max'+' =','0'))\n",
    "    wfile.write('%s %s\\n'%('iranfreqmode '+' =','1'))\n",
    "    wfile.write('%s %s\\n'%('istar_sphere '+' = ','0' ))\n",
    "    wfile.close()\n",
    "\n",
    "    # Dust opacity control file, check name of dustkappa_*** file is the appropriate one.\n",
    "    wfile = open('./dustopac.inp', 'w')\n",
    "    wfile.write('%-15s %s\\n'%('2', 'Format number of this file'))\n",
    "    wfile.write('%-15s %s\\n'%('1', 'Nr of dust species'))\n",
    "    wfile.write('%s\\n'%'============================================================================')\n",
    "    wfile.write('%-15s %s\\n'%('1', 'Way in which this dust species is read'))\n",
    "    wfile.write('%-15s %s\\n'%('0', '0=Thermal grain, 1=Quantum heated'))\n",
    "    wfile.write('%s %s %s\\n'%('10445.micr', '    ', 'Extension of name of dustkappa_***.inp file'))\n",
    "    wfile.write('%s\\n'%'----------------------------------------------------------------------------')\n",
    "    wfile.close()\n",
    "\n",
    "    #Make and print temperature grid, assumed blackbody, **This GRID needs to be THE SAME AS IN PROBLEM_SETUP FILE**\n",
    "    t=278.3*(Lstar**0.25)/np.sqrt(rr/AU)\n",
    "    #print t[:,0,0]\n",
    "    #print rr[:,0,0]/AU\n",
    "    wfile=open('./dust_temperature.dat', 'w')\n",
    "    wfile.write('%d\\n'%1)    # Format number\n",
    "    wfile.write('%d\\n'%(rc.size*tcsize))    # Nr of cells\n",
    "    wfile.write('%d\\n'%1)   # Nr of dust species\n",
    "    for ith in range(tcsize):\n",
    "        for ir in range(rc.size):\n",
    "            wfile.write('%.9e\\n'%(t[ir,ith]))\n",
    "    wfile.close()\n",
    "    \n",
    "\n",
    "    #Read file containing visibility data, extracted in CASA through 'mstonumpyortxt.py' script, and read primary\n",
    "    #beam images\n",
    "    u=[[] for x in vis]\n",
    "    v=[[] for x in vis]\n",
    "    Re=[[] for x in vis]\n",
    "    Im=[[] for x in vis]\n",
    "    w=[[] for x in vis]\n",
    "    pbpad=[[] for x in vis]\n",
    "    for i in np.arange(nvis):\n",
    "        u[i], v[i], Re[i], Im[i], w[i] = np.load(vis[i][:-3]+'.npy')\n",
    "        #Import primary beam (pb) to take its effect into account in the model fitting. \n",
    "        pbcov, header_pbcov = pf.getdata(pbfilenames[i],0, header=True)\n",
    "        #CASA images come as 4D cubes (polarization, frequency, spatial y (north-south) direction, spatial x (east-west) \n",
    "        #direction).\n",
    "        #In the case of dust continuum images we have no polarization or frequency, so removing those dimensions below\n",
    "        pbcov=pbcov[0,0,:,:]\n",
    "        #Randomly a few pixels from the PB computed by CASA have nans. Remove them\n",
    "        pbcov[np.where(np.isnan(pbcov))]=0.0\n",
    "        #Get wavelength which will be a dummy for radmc3d run\n",
    "        wav=1e6*c/(header_pbcov['CRVAL3'])\n",
    "        #Pad PB coverage if needed\n",
    "        pbpad[i]=pbcov #Should be of shape [nxy[i],nxy[i]] as pre-defined internally\n",
    "\n",
    "    if ngal>=1:\n",
    "        if np.any(resolved):\n",
    "    \n",
    "            # Radial grid parameters for galaxy, grid over which the dust density will be computed. Make sure the step is smaller or equal to the pixel size, and that we roughly cover the extent of the image in arcsec\n",
    "            Rmin = 0.00001  # arcsec\n",
    "            dR = 0.01    # arcsec\n",
    "            nR = 256\n",
    "            print('Grid goes out to '+str(dR*nR)+' arcsec radius')\n",
    "            print('Image goes out to '+str(nxy*dxy*180.0/np.pi*3600.0/2.0)+' arcsec radius')\n",
    "            \n",
    "            Rminrad=np.radians(Rmin)\n",
    "            dRrad=np.radians(dR)\n",
    "            \n",
    "            #Set up Gaussian radial profile function for bkg galaxy \n",
    "            def GaussianProfileGalaxy(f0, sigma, Rmin, dR, nR):\n",
    "            sigma *= arcsec\n",
    "            Rmin *= arcsec\n",
    "            dR *= arcsec\n",
    "            R = np.linspace(Rmin, Rmin + dR*nR, nR, endpoint=False)\n",
    "            return f0 * np.exp(-0.5*(R/sigma)**2.0)\n",
    "\n",
    "    \n",
    "    #Function that defines likelihood function and multiplies it by the function computing the prior (defined further below).\n",
    "    #Takes as input the radial grid defined above, and the parameters p that define the model and that will be varied in the fit.\n",
    "    #Prints ln(L)+ln(prior), where L is the likelihood function, in this case just the chi squared of the data.\n",
    "    #If, when calling it, locfiles is specified as an address on the machine, the function prints a numpy save file with the reweighting \n",
    "    #factor, one with the uv table containing model visibilities, and one containing geometry of the belt (inclination, position angle) \n",
    "    #plus RA and Dec offset from the image center. It also returns a model image and lnL.\n",
    "    def lnpostfn(p, locfiles=None):\n",
    "\n",
    "        #Calculate prior.\n",
    "        lnprior = lnpriorfn(p)\n",
    "        if not np.isfinite(lnprior):\n",
    "            return -np.inf\n",
    "    \n",
    "        countpars=0\n",
    "        if useh:\n",
    "            h=p[5]\n",
    "            countpars+=1\n",
    "        else:\n",
    "            h=0.03\n",
    "        \n",
    "        if star:\n",
    "            fstar=p[5+countpars]\n",
    "            countpars+=1\n",
    "\n",
    "        ciao = str(uuid.uuid4())\n",
    "        os.system('mkdir '+'./'+ciao)\n",
    "        os.chdir('./'+ciao)\n",
    "        os.system('cp '+'../dustopac.inp .')\n",
    "        os.system('cp '+'../wavelength_micron.inp .')\n",
    "        os.system('cp '+'../radmc3d.inp .')\n",
    "        os.system('cp '+'../dust_temperature.dat .')\n",
    "        os.system('cp '+'../dustkappa_10445.micr.inp .')\n",
    "    \n",
    "        mdisk=1e-7 #Mearth, dummy just to make sure it's optically thin, which it is anyway.\n",
    "        problem_setup_cont_gauss.problem_setup([mdisk, p[1]*dist, p[2]*dist, h, rmin, rmax, nr, nth])\n",
    "\n",
    "        ##############\n",
    "        ## RUN RADMC AND READ OUTPUT\n",
    "        ##############\n",
    "        \n",
    "        # Run\n",
    "        os.system(radmcgalapath+'/radmc-3d/version_0.41/srcnoprint/radmc3d image lambda '+str(wav)+' incl '+str(p[3])+\n",
    "                  ' posang '+str(90.0+p[4])+' sizeau '+str(sizeau)+' npix '+str(npix)+' imageunform nostar')\n",
    "        # Read\n",
    "        imag     =     radmc3dPy.image.readImage(binary=True)\n",
    "\n",
    "        #Normalize model using total flux density which is free parameter\n",
    "        imagjypixdistscaled = imag.imageJyppix[:,:,0]*p[0]/np.sum(imag.imageJyppix[:,:,0])\n",
    "\n",
    "        #Pad model so that image is large enough to sample shortest visibility spacings\n",
    "        modpad=np.zeros((nxy,nxy))\n",
    "        modpad[(nxy/2-npix/2):(nxy/2+npix/2),(nxy/2-npix/2):(nxy/2+npix/2)]+=imagjypixdistscaled\n",
    "\n",
    "\n",
    "        # Here compute model complex visibilities stored in complex array vis by Fourier Transforming the model image multiplied \n",
    "        # by the primary beam (simulating the response of the antennas)\tand evaluating this FT at the u-v points sampled \n",
    "        # by the interferometer. Then, rotate the visibilities (equivalent to rotating the model image) according to the position angle PA.\n",
    "        # Then,  phase-shift the visibilities (equivalent to shifting the star from the image center), according to dRA and dDec.\n",
    "        # Finally, return the chisquared of the model visibilities as:\n",
    "        # [(Real_data-Real_model)^2+(Imaginary_data-Imaginary_model)^2]*weight summed over all u-v points.\n",
    "        vismodel=[[] for x in vis]\n",
    "        warr=[[] for x in vis]\n",
    "        dRArad=[[] for x in vis]\n",
    "        dDecrad=[[] for x in vis]\n",
    "        for i in np.arange(nvis):\n",
    "            dRArad[i], dDecrad[i] = p[5+countpars]/3600.0*np.pi/180.0, p[6+countpars]/3600.0*np.pi/180.0\n",
    "            vismodel[i] = sampleImage(np.ascontiguousarray(np.flip(modpad*pbpad[i], axis=0)), dxy, u[i], v[i]\n",
    "                                      , dRA=dRArad[i], dDec=dDecrad[i])\n",
    "            warr[i] = p[7+countpars]\n",
    "            countpars+=3\n",
    "        \n",
    "            if star:\n",
    "                #Then add the star\n",
    "                vismodelstar=np.zeros(u[i].size, dtype=np.complex_)\n",
    "                vismodelstar.real+=fstar\n",
    "                #Phase shift star in the visibilities in the same way as model is being shifted by Galario. So star is in geometric center of ring.\n",
    "                theta = u[i]*2.0*np.pi*(dRArad[i]) + v[i]*2.0*np.pi*(dDecrad[i])\n",
    "                vismodelstar = (np.real(vismodelstar) + 1j*np.imag(vismodelstar)) * (np.cos(theta) + 1j*np.sin(theta)) #NB This is a multiplication in a complex number sense! Which is the same as a rotation in [Re, Im] space\n",
    "                vismodel[i]+=vismodelstar\n",
    "                \n",
    "        if ngal>=1:\n",
    "            for i in np.arange(ngal):\n",
    "                \n",
    "                fbkg, dRAbkgrad, dDecbkgrad = p[5+countpars], p[6+countpars]/3600.0*np.pi/180.0, p[7+countpars]/3600.0*np.pi/180.0\n",
    "                \n",
    "                if resolved[i]:\n",
    "                    sigmagal, PAgal, incgal = p[8+countpars], p[9+countpars]*deg, p[10+countpars]*deg\n",
    "                    #Then add the bkg source as a 2D Gaussian inclined with Galario functions\n",
    "                    fgal = GaussianProfileGalaxy(1.0, sigmagal, Rmin, dR, nR)\n",
    "                    #Make a separate image with offset source\n",
    "                    imbkgonly = sweep(fgal, Rminrad, dRrad, nxy, dxy, inc=incgal)\n",
    "                    for j in np.arange(nvis):\n",
    "                        visbkg = sampleImage(imbkgonly*fbkg*\n",
    "                                             pbpad[j][np.int(pbpad.shape[0]/2.0+p[7+countpars]/pxsz), \n",
    "                                                   np.int(pbpad.shape[1]/2.0-p[6+countpars]/pxsz)]/np.sum(imbkgonly), \n",
    "                                             dxy[j], u[j], v[j], PA=PAgal, dRA=dRAbkgrad+dRArad[j], dDec=dDecbkgrad+dDecrad[j])\n",
    "                        vismodel[j]+=visbkg\n",
    "                    countpars+=6\n",
    "                else:\n",
    "                    for j in np.arange(nvis):\n",
    "                        #Then add bkg point source\n",
    "                        visbkg=np.zeros(u[j].size, dtype=np.complex_)\n",
    "                        visbkg.real+=fbkg*pbpad[np.int(pbpad.shape[0]/2.0+p[7+countpars]/pxsz), np.int(pbpad.shape[1]/2.0-p[6+countpars]/pxsz)]\n",
    "                        #Phase shift bkg in the visibilities in the same way as model is being shifted by Galario.\n",
    "                        theta = u[j]*2.0*np.pi*(dRAbkgrad+dRArad[j]) + v[j]*2.0*np.pi*(dDecbkgrad+dDecrad[j])\n",
    "                        visbkg = (np.real(visbkg) + 1j*np.imag(visbkg)) * (np.cos(theta) + 1j*np.sin(theta))\n",
    "                        vismodel[j]+=visbkg\n",
    "                    countpars+=3  \n",
    "        \n",
    "        chi2=[[] for x in vismodel]\n",
    "        lnL=lnprior\n",
    "        for i in np.arange(vismodel):\n",
    "            chi2[i]=np.sum(((np.real(vismodel[i])-Re[i])**2.0+(np.imag(vismodel[i])-Im[i])**2.0)*w[i])\n",
    "            lnL+=-0.5*(chi2[i]*warr[i] + np.sum(2.0*np.log(2.0*np.pi/warr[i]/w[i])))\n",
    "\n",
    "        # Here print useful things if needed for postprocessing, as described above\n",
    "        if locfiles:\n",
    "            warr=[wtfact]\n",
    "            np.save('../'+locfiles+'/warr.npy', warr)\n",
    "            Re_resid=Re-vismodel.real\n",
    "            Im_resid=Im-vismodel.imag\n",
    "            np.save('../'+locfiles+'/'+tag+'_uvtable_model.npy', [u, v, vismodel.real, vismodel.imag, w])\n",
    "            np.save('../'+locfiles+'/'+tag+'_uvtable_resid.npy', [u, v, Re_resid, Im_resid, w])\n",
    "            np.save('../'+locfiles+'/bestfitshiftPAinc_rad.npy', [incl*np.pi/180.0, posang*np.pi/180.0, dRArad, dDecrad])\n",
    "            os.chdir('..')\n",
    "            os.system('rm -r '+ciao)\n",
    "            return modpad, pxsz, -0.5*(chi2*wtfact) #-0.5*(chi2*wtfact + np.sum(2.0*np.log(2.0*np.pi/wtfact/w)))\n",
    "    \n",
    "    \n",
    "        os.chdir('..')\n",
    "    \n",
    "        os.system('rm -r '+ciao)\n",
    "\n",
    "        # To conclude, return -chisquare/2 + ln(prior), where chisquare is rescaled by a reweighting factor wtfact which we leave as free parameter.\n",
    "        # The latter is needed as it has been found that the weights delivered by ALMA and extracted from CASA are incorrect by varying factors\n",
    "        # which depend on the dataset, and this influences the uncertainty on the model parameters that we obtain from fitting the model to the data.\n",
    "        # The chisquare is also added to np.sum(2.0*np.log(2.0*np.pi/wtfact/w)) which acts to normalise the probability so that its integral is one -\n",
    "        # -  in other words exp(-chisquare/2)=model probability is 1 when integrated over the entire parameter space. See emcee documentation, but \n",
    "        # note that the latter does not affect the outcome of the fit, except (perhaps?) the value of the reweighting factor.\n",
    "        return lnL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Here define prior probability distributions for each parameter. \n",
    "    # We choose uninformative priors, so the probability is 1 for a model where all parameters are within their allowed ranges (which we define here)\n",
    "    # And 0 if we fall outside of these ranges. In other words, ln(prior)=0 if parameters fall in the allowed ranges (regardless of what they are)\n",
    "    # and ln(prior)=-infinity if any of them falls outside the allowed ranges.\n",
    "    def lnpriorfn(p):\n",
    "        for i in range(len(p)):\n",
    "            if p[i] > priors_up[i] or p[i] < priors_dwn[i]:\n",
    "                return -np.inf\n",
    "        return 0.0\n",
    "\n",
    "    # Starting point in our parameter space search, for each parameter. Order is\n",
    "    # fstar, f0, R0, sigma, inc, PA, dRA, dDec, wtfact\n",
    "    p0 = pars_init\n",
    "\n",
    "    print('Setting up sampler...')\n",
    "    ndim = len(pars_init)       \t    # number of dimensions of the parameter space = number of model parameters\n",
    "    nwalkers = ndim*10              # number of walkers that will undergo the MCMC\n",
    "    #nthreads = 1               # CPU threads that emcee should use. Commented out as 'Pool' computes that automatically\n",
    "    nsteps = 10    \t    # total number of steps to run the MCMC for.\n",
    "\n",
    "    # Starting point in our parameter space search, for each parameter, here expanded FOR EACH OF THE nwalkers walkers.\n",
    "    # For each parameter, it's good to start walkers in a 'Gaussian distribution' around the first guess p0, where the first \n",
    "    # guess should be 'well guessed' (e.g. by looking at the imaging of the data). \n",
    "    pos = [p0 + np.asarray([0.1]*ndim)*np.asarray(p0)*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "\n",
    "    # Define 'backend' which is practically a file which holds the result of the MCMC computation AS IT IS RUNNING.\n",
    "    # This ensures we can recover the result not only in the future, but also if something goes wrong and the MCMC crashes\n",
    "    backend=emcee3.backends.HDFBackend(backendaddress)\n",
    "    # This command wipes what's currently stored in the backend opened above - so make sure you don't use this command on a backend \n",
    "    # containing something important!\n",
    "    #backend.reset(nwalkers,ndim)\n",
    "\n",
    "    #import the Pool function which allows the computation to be distributed amongst different cores of the machine we are running on,\n",
    "    #saving a considerable amount of time.\n",
    "    #Usage of different cores can be seen through the terminal command 'mpstat -P ALL 1' while the MCMC is running.\n",
    "    from multiprocessing import Pool\n",
    "\n",
    "    # Define object of EnsembleSampler class from emcee package. Basically this is the object the computation gets run onto.\n",
    "    # See https://emcee.readthedocs.io/en/latest for a full description of the object, what function/parameters it has, and\n",
    "    # in general how the MCMC fit works.\n",
    "    sampler = emcee3.EnsembleSampler(nwalkers, ndim, lnpostfn, pool=Pool(), backend=backend)#, pool=Pool())\n",
    "\n",
    "    return pos, sampler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
